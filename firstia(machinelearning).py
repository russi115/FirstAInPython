# -*- coding: utf-8 -*-
"""FirstIA(machineLearning).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-6LbUSSJG0L2v67KHQ30lKuRMtsTnYxt
"""

import numpy as np 
import scipy as sc
import matplotlib.pyplot as plt

from sklearn.datasets import make_circles

# crear el dataset

n = 500
p = 2

X, Y = make_circles(n_samples=n, factor=0.5, noise=0.05)
Y = Y[:, np.newaxis]

plt.scatter(X[Y[:, 0] == 0, 0], X[Y[:, 0]== 0,1], c="skyblue")
plt.scatter(X[Y[:, 0] == 1, 0], X[Y[:, 0]== 1,1], c="salmon")
plt.axis("equal") 

plt.show()

#clase de la capa de la red
class neural_layer():
  def __init__(self, n_conn, n_neur, act_f):
    self.act_f=act_f
    self.b = np.random.rand(1, n_neur)      * 2 -1
    self.w = np.random.rand(n_conn, n_neur) * 2 -1

#funciones de activacion

sing = (lambda x: 1/(1+np.e ** (-x)),
        lambda x: x * (1-x))

relu = lambda x: np.maximum(0, x)

_x = np.linspace(-5,5,100)
plt.plot(_x, sing[0](_x))

l0 = neural_layer(p, 4, sing)
l1 = neural_layer(4, 8, sing)
#...


def create_nn(topology, act_f):
  nn = []
  for l, layer in enumerate(topology[:-1]):
    nn.append(neural_layer(topology[l], topology[l+1], act_f))

  return nn

topology = [p, 4, 8, 1]

neural_net = create_nn(topology, sing)

l2_cost = (lambda Yp, Yr: np.mean((Yp-Yr)**2),
           lambda Yp, Yr: (Yp - Yr))

def train(neural_net, X, Y, l2_cost, lr=0.5, train= True):

  out = [(None, X)]
  #forward pass
  for l, layer in enumerate(neural_net):

    z = out[-1][1] @ neural_net[l].w + neural_net[l].b
    a = neural_net[l].act_f[0](z)

    out.append((z,a))

  if train:
    #backward pass
    deltas = []

    for l in reversed(range(0, len(neural_net))):
      z= out[l+1][0]
      a= out[l+1][1]

      if l == len(neural_net)-1:
        deltas.insert(0, l2_cost[1](a, Y)* neural_net[l].act_f[1](a))
      else:
        deltas.insert(0, deltas[0] @ _W.T * neural_net[l].act_f[1](a))

      _W = neural_net[l].w

      #gradient descent
      neural_net[l].b = neural_net[l].b - np.mean(deltas[0], axis=0, keepdims= True) * lr
      neural_net[l].w = neural_net[l].w - out[l][1].T @ deltas[0] * lr
    
  return out[-1][1]

train(neural_net, X, Y, l2_cost, 0.5)
print("")

import time 
from IPython.display import clear_output

neural_n = create_nn(topology, sing)

loss = []

for i in range(5000):

  #entrenamos la red
  pY = train(neural_n, X, Y, l2_cost, lr=0.04)

  if i % 25 == 0:

    loss.append(l2_cost[0](pY, Y))

    res = 50

    _X0 = np.linspace(-1.5, 1.5, res)
    _X1 = np.linspace(-1.5, 1.5, res)

    _Y = np.zeros((res, res))

    for i0, X0 in enumerate(_X0):
      for i1, X1 in enumerate (_X1):
        _Y[i0, i1] = train(neural_n, np.array([[X0, X1]]), Y, l2_cost, train=False)[0][0]

    plt.pcolormesh(_X0, _X1, _Y, cmap="coolwarm")
    plt.axis("equal")

    plt.scatter(X[Y[:,0]== 0, 0], X[Y[:,0] == 0,1], c="skyblue")
    plt.scatter(X[Y[:,0]== 1, 0], X[Y[:,0] == 1,1], c="salmon")

    clear_output(wait=True)
    plt.show()
    plt.plot(range(len(loss)), loss)
    plt.show()
    time.sleep(0.5)